{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "aqmtjj0bgKae"
      },
      "outputs": [],
      "source": [
        "df2 = pd.read_csv(\"/content/UNSW_preview.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mjns7YM-gShY",
        "outputId": "85dbcd00-3f7b-4f3c-e384-05d3ba6a2865"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['dur',\n",
              " 'proto',\n",
              " 'service',\n",
              " 'state',\n",
              " 'spkts',\n",
              " 'dpkts',\n",
              " 'sbytes',\n",
              " 'dbytes',\n",
              " 'rate',\n",
              " 'sload',\n",
              " 'dload',\n",
              " 'sloss',\n",
              " 'dloss',\n",
              " 'sinpkt',\n",
              " 'dinpkt',\n",
              " 'sjit',\n",
              " 'djit',\n",
              " 'swin',\n",
              " 'stcpb',\n",
              " 'dtcpb',\n",
              " 'dwin',\n",
              " 'tcprtt',\n",
              " 'synack',\n",
              " 'ackdat',\n",
              " 'smean',\n",
              " 'dmean',\n",
              " 'trans_depth',\n",
              " 'response_body_len',\n",
              " 'ct_src_dport_ltm',\n",
              " 'ct_dst_sport_ltm',\n",
              " 'is_ftp_login',\n",
              " 'ct_ftp_cmd',\n",
              " 'ct_flw_http_mthd',\n",
              " 'is_sm_ips_ports',\n",
              " 'attack_cat',\n",
              " 'label']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(df2.columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KA2h3nlptYV_",
        "outputId": "22c0e3f6-814f-4662-9e5b-f06ec239938c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['udp', 'arp', 'tcp', 'igmp', 'ospf', 'sctp', 'gre', 'ggp', 'ip',\n",
              "       'ipnip', 'st2', 'argus', 'chaos', 'egp', 'emcon', 'nvp', 'pup',\n",
              "       'xnet', 'mux', 'dcn', 'hmp', 'prm', 'trunk-1', 'trunk-2',\n",
              "       'xns-idp', 'leaf-1', 'leaf-2', 'irtp', 'rdp', 'netblt', 'mfe-nsp',\n",
              "       'merit-inp', '3pc', 'idpr', 'ddp', 'idpr-cmtp', 'tp++', 'ipv6',\n",
              "       'sdrp', 'ipv6-frag', 'ipv6-route', 'idrp', 'mhrp', 'i-nlsp', 'rvd',\n",
              "       'mobile', 'narp', 'skip', 'tlsp', 'ipv6-no', 'any', 'ipv6-opts',\n",
              "       'cftp', 'sat-expak', 'ippc', 'kryptolan', 'sat-mon', 'cpnx', 'wsn',\n",
              "       'pvp', 'br-sat-mon', 'sun-nd', 'wb-mon', 'vmtp', 'ttp', 'vines',\n",
              "       'nsfnet-igp', 'dgp', 'eigrp', 'tcf', 'sprite-rpc', 'larp', 'mtp',\n",
              "       'ax.25', 'ipip', 'aes-sp3-d', 'micp', 'encap', 'pri-enc', 'gmtp',\n",
              "       'ifmp', 'pnni', 'qnx', 'scps', 'cbt', 'bbn-rcc', 'igp', 'bna',\n",
              "       'swipe', 'visa', 'ipcv', 'cphb', 'iso-tp4', 'wb-expak', 'sep',\n",
              "       'secure-vmtp', 'xtp', 'il', 'rsvp', 'unas', 'fc', 'iso-ip',\n",
              "       'etherip', 'pim', 'aris', 'a/n', 'ipcomp', 'snp', 'compaq-peer',\n",
              "       'ipx-n-ip', 'pgm', 'vrrp', 'l2tp', 'zero', 'ddx', 'iatp', 'stp',\n",
              "       'srp', 'uti', 'sm', 'smp', 'isis', 'ptp', 'fire', 'crtp', 'crudp',\n",
              "       'sccopmce', 'iplt', 'pipe', 'sps', 'ib'], dtype=object)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/Testing.csv\")\n",
        "df['proto'].unique()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uDYkacGMiux1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_parquet(\"/content/UNSW_NB15_testing-set.parquet\")\n",
        "df.to_csv(\"Testing.csv\", index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3XDMncaogUWL",
        "outputId": "78e99c40-e434-46b3-d56c-ff7bb9c2607f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ğŸ”¹ Training Model: LOGISTIC_REGRESSION\n",
            "âœ” Accuracy: 0.6709\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00       677\n",
            "      Backdoor       0.00      0.00      0.00       583\n",
            "           DoS       0.25      0.02      0.03      4089\n",
            "      Exploits       0.48      0.74      0.58     11132\n",
            "       Fuzzers       0.22      0.52      0.31      6062\n",
            "       Generic       0.99      0.96      0.98     18871\n",
            "        Normal       0.89      0.62      0.73     37000\n",
            "Reconnaissance       0.45      0.73      0.56      3496\n",
            "     Shellcode       0.00      0.00      0.00       378\n",
            "         Worms       0.00      0.00      0.00        44\n",
            "\n",
            "      accuracy                           0.67     82332\n",
            "     macro avg       0.33      0.36      0.32     82332\n",
            "  weighted avg       0.74      0.67      0.68     82332\n",
            "\n",
            "ğŸ’¾ Saved: logistic_regression_cyber_classifier.pkl\n",
            "\n",
            "ğŸ”¹ Training Model: DECISION_TREE\n",
            "âœ” Accuracy: 0.7474\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.02      0.03      0.02       677\n",
            "      Backdoor       0.03      0.08      0.04       583\n",
            "           DoS       0.25      0.23      0.24      4089\n",
            "      Exploits       0.61      0.70      0.65     11132\n",
            "       Fuzzers       0.30      0.51      0.38      6062\n",
            "       Generic       0.98      0.98      0.98     18871\n",
            "        Normal       0.93      0.76      0.84     37000\n",
            "Reconnaissance       0.91      0.79      0.84      3496\n",
            "     Shellcode       0.29      0.52      0.37       378\n",
            "         Worms       0.46      0.36      0.41        44\n",
            "\n",
            "      accuracy                           0.75     82332\n",
            "     macro avg       0.48      0.50      0.48     82332\n",
            "  weighted avg       0.80      0.75      0.77     82332\n",
            "\n",
            "ğŸ’¾ Saved: decision_tree_cyber_classifier.pkl\n",
            "\n",
            "ğŸ”¹ Training Model: RANDOM_FOREST\n",
            "âœ” Accuracy: 0.7698\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00       677\n",
            "      Backdoor       0.03      0.07      0.04       583\n",
            "           DoS       0.53      0.11      0.18      4089\n",
            "      Exploits       0.59      0.84      0.69     11132\n",
            "       Fuzzers       0.31      0.56      0.39      6062\n",
            "       Generic       1.00      0.97      0.98     18871\n",
            "        Normal       0.94      0.78      0.85     37000\n",
            "Reconnaissance       0.93      0.80      0.86      3496\n",
            "     Shellcode       0.43      0.46      0.45       378\n",
            "         Worms       0.25      0.05      0.08        44\n",
            "\n",
            "      accuracy                           0.77     82332\n",
            "     macro avg       0.50      0.46      0.45     82332\n",
            "  weighted avg       0.82      0.77      0.78     82332\n",
            "\n",
            "ğŸ’¾ Saved: random_forest_cyber_classifier.pkl\n",
            "\n",
            "ğŸ”¹ Training Model: XGBOOST\n",
            "âœ” Accuracy: 0.7860\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Analysis       0.00      0.00      0.00       677\n",
            "      Backdoor       0.24      0.06      0.09       583\n",
            "           DoS       0.59      0.08      0.14      4089\n",
            "      Exploits       0.57      0.91      0.70     11132\n",
            "       Fuzzers       0.33      0.57      0.42      6062\n",
            "       Generic       1.00      0.97      0.98     18871\n",
            "        Normal       0.95      0.79      0.86     37000\n",
            "Reconnaissance       0.93      0.81      0.86      3496\n",
            "     Shellcode       0.40      0.65      0.49       378\n",
            "         Worms       0.48      0.23      0.31        44\n",
            "\n",
            "      accuracy                           0.79     82332\n",
            "     macro avg       0.55      0.51      0.49     82332\n",
            "  weighted avg       0.83      0.79      0.79     82332\n",
            "\n",
            "ğŸ’¾ Saved: xgboost_cyber_classifier.pkl\n",
            "\n",
            "==========================\n",
            " ALL MODELS TRAINED & SAVED SUCCESSFULLY\n",
            "==========================\n",
            "ğŸ“ logistic_regression_cyber_classifier.pkl\n",
            "ğŸ“ decision_tree_cyber_classifier.pkl\n",
            "ğŸ“ random_forest_cyber_classifier.pkl\n",
            "ğŸ“ xgboost_cyber_classifier.pkl\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "train_df = pd.read_csv('/content/Training.csv')\n",
        "test_df  = pd.read_csv('/content/Testing.csv')\n",
        "\n",
        "\n",
        "train_df = train_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "test_df  = test_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "X_train = train_df.drop(['attack_cat', 'label'], axis=1)\n",
        "y_train = train_df['attack_cat']\n",
        "\n",
        "X_test = test_df.drop(['attack_cat', 'label'], axis=1)\n",
        "y_test = test_df['attack_cat']\n",
        "\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_train = label_encoder.fit_transform(y_train)\n",
        "y_test = label_encoder.transform(y_test)\n",
        "\n",
        "\n",
        "categorical_cols = ['proto', 'service', 'state']\n",
        "numeric_cols = [col for col in X_train.columns if col not in categorical_cols]\n",
        "\n",
        "\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
        "    ('scale', StandardScaler(), numeric_cols)\n",
        "])\n",
        "\n",
        "\n",
        "models = {\n",
        "    \"logistic_regression\": LogisticRegression(max_iter=500),\n",
        "    \"decision_tree\": DecisionTreeClassifier(),\n",
        "    \"random_forest\": RandomForestClassifier(n_estimators=120),\n",
        "    \"xgboost\": XGBClassifier(eval_metric='mlogloss', n_estimators=120)\n",
        "}\n",
        "\n",
        "\n",
        "saved_files = []\n",
        "\n",
        "for model_name, model in models.items():\n",
        "\n",
        "    print(f\"\\n Training Model: {model_name.upper()}\")\n",
        "\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocess', preprocessor),\n",
        "        ('model', model)\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "    y_pred = pipeline.predict(X_test)\n",
        "\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy: {acc:.4f}\")\n",
        "    print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))\n",
        "\n",
        "\n",
        "    filename = f\"{model_name}_cyber_classifier.pkl\"\n",
        "    joblib.dump({\"model\": pipeline, \"label_encoder\": label_encoder}, filename)\n",
        "\n",
        "    saved_files.append(filename)\n",
        "    print(f\"ğŸ’¾ Saved: {filename}\")\n",
        "\n",
        "\n",
        "print(\" ALL MODELS TRAINED & SAVED SUCCESSFULLY\")\n",
        "for file in saved_files:\n",
        "    print(\"Saved\", file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wv5SRYd3nBBM",
        "outputId": "418fe0fb-1d8d-4307-a5f5-3c6ca16b23f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics saved and confusion matrices generated.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "os.makedirs(\"model_metrics\", exist_ok=True)\n",
        "os.makedirs(\"confusion_matrices\", exist_ok=True)\n",
        "\n",
        "test_df = pd.read_csv(\"/content/Testing.csv\")\n",
        "\n",
        "y_true = test_df['attack_cat']\n",
        "label_map = joblib.load(\"logistic_regression_cyber_classifier.pkl\")['label_encoder']\n",
        "\n",
        "models = {\n",
        "    \"logistic_regression\": \"/content/logistic_regression_cyber_classifier.pkl\",\n",
        "    \"decision_tree\": \"/content/decision_tree_cyber_classifier.pkl\",\n",
        "    \"random_forest\": \"/content/random_forest_cyber_classifier.pkl\",\n",
        "    \"xgboost\": \"/content/xgboost_cyber_classifier.pkl\"\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, file in models.items():\n",
        "    model_data = joblib.load(file)\n",
        "    model = model_data['model']\n",
        "\n",
        "    X_test = test_df.drop(['attack_cat', 'label'], axis=1)\n",
        "    y_pred = label_map.inverse_transform(model.predict(X_test))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=label_map.classes_)\n",
        "\n",
        "    plt.figure(figsize=(10,8))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"viridis\", xticklabels=label_map.classes_, yticklabels=label_map.classes_)\n",
        "    plt.title(f\"{name} Confusion Matrix\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.savefig(f\"confusion_matrices/{name}_confusion_matrix.png\")\n",
        "    plt.close()\n",
        "\n",
        "    results.append({\n",
        "        \"Model\": name,\n",
        "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"Precision\": precision_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"Recall\": recall_score(y_true, y_pred, average=\"macro\", zero_division=0),\n",
        "        \"F1 Score\": f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df.to_excel(\"model_metrics/model_scores.xlsx\", index=False)\n",
        "\n",
        "print(\"Metrics saved and confusion matrices generated.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dma5nzNwnVpE",
        "outputId": "48cb085f-60ca-4e8c-80d4-d06f61b19f05"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting crewai\n",
            "  Downloading crewai-1.6.0-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting groq\n",
            "  Downloading groq-0.36.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (1.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: shap in /usr/local/lib/python3.12/dist-packages (0.50.0)\n",
            "Collecting appdirs>=1.4.4 (from crewai)\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting chromadb~=1.1.0 (from crewai)\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: click>=8.1.7 in /usr/local/lib/python3.12/dist-packages (from crewai) (8.3.1)\n",
            "Collecting instructor>=1.3.3 (from crewai)\n",
            "  Downloading instructor-1.13.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting json-repair==0.25.2 (from crewai)\n",
            "  Downloading json_repair-0.25.2-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting json5>=0.10.0 (from crewai)\n",
            "  Downloading json5-0.12.1-py3-none-any.whl.metadata (36 kB)\n",
            "Collecting jsonref>=1.1.0 (from crewai)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: mcp>=1.16.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.22.0)\n",
            "Requirement already satisfied: openai>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.8.1)\n",
            "Requirement already satisfied: openpyxl>=3.1.5 in /usr/local/lib/python3.12/dist-packages (from crewai) (3.1.5)\n",
            "Requirement already satisfied: opentelemetry-api>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.30.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.37.0)\n",
            "Collecting pdfplumber>=0.11.4 (from crewai)\n",
            "  Downloading pdfplumber-0.11.8-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker==2.7.0 (from crewai)\n",
            "  Downloading portalocker-2.7.0-py2.py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: pydantic-settings>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.12.0)\n",
            "Requirement already satisfied: pydantic>=2.11.9 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.12.3)\n",
            "Requirement already satisfied: pyjwt>=2.9.0 in /usr/local/lib/python3.12/dist-packages (from crewai) (2.10.1)\n",
            "Requirement already satisfied: python-dotenv>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from crewai) (1.2.1)\n",
            "Requirement already satisfied: regex>=2024.9.11 in /usr/local/lib/python3.12/dist-packages (from crewai) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers>=0.20.3 in /usr/local/lib/python3.12/dist-packages (from crewai) (0.22.1)\n",
            "Collecting tomli-w>=1.1.0 (from crewai)\n",
            "  Downloading tomli_w-1.2.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting tomli>=2.0.2 (from crewai)\n",
            "  Downloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
            "Collecting uv>=0.4.25 (from crewai)\n",
            "  Downloading uv-0.9.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq) (0.28.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.12/dist-packages (from shap) (4.67.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.12/dist-packages (from shap) (25.0)\n",
            "Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.12/dist-packages (from shap) (0.0.8)\n",
            "Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.12/dist-packages (from shap) (0.60.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from shap) (3.1.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq) (3.11)\n",
            "Collecting build>=1.0.3 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading build-1.3.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting pybase64>=1.4.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (0.38.0)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.38.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (1.76.0)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (0.20.0)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (9.1.2)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (3.11.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb~=1.1.0->crewai) (4.25.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (2025.11.12)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.16.0)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.13.2)\n",
            "Collecting diskcache>=5.6.3 (from instructor>=1.3.3->crewai)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: docstring-parser<1.0,>=0.16 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (0.17.0)\n",
            "Requirement already satisfied: jinja2<4.0.0,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (3.1.6)\n",
            "Collecting jiter<0.12,>=0.6.1 (from instructor>=1.3.3->crewai)\n",
            "  Downloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting pre-commit>=4.3.0 (from instructor>=1.3.3->crewai)\n",
            "  Downloading pre_commit-4.5.0-py2.py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.0 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (2.41.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.3 in /usr/local/lib/python3.12/dist-packages (from instructor>=1.3.3->crewai) (2.32.4)\n",
            "Collecting ty>=0.0.1a23 (from instructor>=1.3.3->crewai)\n",
            "  Downloading ty-0.0.1a28-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx-sse>=0.4 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.16.0->crewai) (0.4.3)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.16.0->crewai) (0.0.20)\n",
            "Requirement already satisfied: sse-starlette>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.16.0->crewai) (3.0.3)\n",
            "Requirement already satisfied: starlette>=0.27 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.16.0->crewai) (0.48.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.1 in /usr/local/lib/python3.12/dist-packages (from mcp>=1.16.0->crewai) (0.4.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba>=0.54->shap) (0.43.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl>=3.1.5->crewai) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.30.0->crewai) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.72.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (1.37.0)\n",
            "Requirement already satisfied: protobuf<7.0,>=5.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-proto==1.37.0->opentelemetry-exporter-otlp-proto-http>=1.30.0->crewai) (5.29.5)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.30.0->crewai) (0.58b0)\n",
            "Collecting pdfminer.six==20251107 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pdfminer_six-20251107-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber>=0.11.4->crewai) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber>=0.11.4->crewai)\n",
            "  Downloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (67 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber>=0.11.4->crewai) (3.4.4)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20251107->pdfplumber>=0.11.4->crewai) (43.0.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=2.11.9->crewai) (0.7.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers>=0.20.3->crewai) (0.36.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.9.1->instructor>=1.3.3->crewai) (1.22.0)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.20.3->crewai) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.20.3->crewai) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers>=0.20.3->crewai) (1.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.30.0->crewai) (3.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2<4.0.0,>=3.1.4->instructor>=1.3.3->crewai) (3.0.3)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb~=1.1.0->crewai) (0.29.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.43.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (1.9.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (25.9.23)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.14.0)\n",
            "INFO: pip is looking at multiple versions of opentelemetry-exporter-otlp-proto-grpc to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb~=1.1.0->crewai)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb~=1.1.0->crewai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting cfgv>=2.0.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading cfgv-3.5.0-py2.py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting identify>=1.0.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading identify-2.6.15-py2.py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting nodeenv>=0.11.1 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading nodeenv-1.9.1-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting virtualenv>=20.10.0 (from pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading virtualenv-20.35.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb~=1.1.0->crewai) (2.19.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb~=1.1.0->crewai) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (3.5 kB)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai)\n",
            "  Downloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb~=1.1.0->crewai) (15.0.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber>=0.11.4->crewai) (2.0.0)\n",
            "Requirement already satisfied: cachetools<7.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (6.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (4.9.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb~=1.1.0->crewai) (0.1.2)\n",
            "Collecting distlib<1,>=0.3.7 (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai)\n",
            "  Downloading distlib-0.4.0-py2.py3-none-any.whl.metadata (5.2 kB)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.12/dist-packages (from virtualenv>=20.10.0->pre-commit>=4.3.0->instructor>=1.3.3->crewai) (4.5.0)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb~=1.1.0->crewai) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20251107->pdfplumber>=0.11.4->crewai) (2.23)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb~=1.1.0->crewai) (0.6.1)\n",
            "Downloading crewai-1.6.0-py3-none-any.whl (641 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m641.8/641.8 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json_repair-0.25.2-py3-none-any.whl (12 kB)\n",
            "Downloading portalocker-2.7.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading groq-0.36.0-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m137.3/137.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading instructor-1.13.0-py3-none-any.whl (160 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m160.9/160.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.12.1-py3-none-any.whl (36 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading pdfplumber-0.11.8-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20251107-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli-2.3.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (250 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m250.1/250.1 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomli_w-1.2.0-py3-none-any.whl (6.7 kB)\n",
            "Downloading uv-0.9.13-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (21.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.7/21.7 MB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.3.0-py3-none-any.whl (23 kB)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.11.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (358 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m358.8/358.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.2-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pre_commit-4.5.0-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m226.4/226.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-5.1.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ty-0.0.1a28-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading cfgv-3.5.0-py2.py3-none-any.whl (7.4 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.7.1-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (517 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m517.7/517.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading identify-2.6.15-py2.py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nodeenv-1.9.1-py2.py3-none-any.whl (22 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.22.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading virtualenv-20.35.4-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m51.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (456 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m456.8/456.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading distlib-0.4.0-py2.py3-none-any.whl (469 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=e92188f40e85a6900fd6e94864165c7f7b207e58289e4c188df9be813604a4ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, distlib, appdirs, virtualenv, uvloop, uv, urllib3, ty, tomli-w, tomli, pyproject_hooks, pypdfium2, pybase64, portalocker, nodeenv, mmh3, jsonref, json5, json-repair, jiter, identify, humanfriendly, httptools, diskcache, cfgv, bcrypt, backoff, watchfiles, pre-commit, coloredlogs, build, posthog, pdfminer.six, onnxruntime, groq, pdfplumber, kubernetes, instructor, opentelemetry-exporter-otlp-proto-grpc, chromadb, crewai\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: jiter\n",
            "    Found existing installation: jiter 0.12.0\n",
            "    Uninstalling jiter-0.12.0:\n",
            "      Successfully uninstalled jiter-0.12.0\n",
            "Successfully installed appdirs-1.4.4 backoff-2.2.1 bcrypt-5.0.0 build-1.3.0 cfgv-3.5.0 chromadb-1.1.1 coloredlogs-15.0.1 crewai-1.6.0 diskcache-5.6.3 distlib-0.4.0 durationpy-0.10 groq-0.36.0 httptools-0.7.1 humanfriendly-10.0 identify-2.6.15 instructor-1.13.0 jiter-0.11.1 json-repair-0.25.2 json5-0.12.1 jsonref-1.1.0 kubernetes-34.1.0 mmh3-5.2.0 nodeenv-1.9.1 onnxruntime-1.23.2 opentelemetry-exporter-otlp-proto-grpc-1.37.0 pdfminer.six-20251107 pdfplumber-0.11.8 portalocker-2.7.0 posthog-5.4.0 pre-commit-4.5.0 pybase64-1.4.2 pypdfium2-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 tomli-2.3.0 tomli-w-1.2.0 ty-0.0.1a28 urllib3-2.3.0 uv-0.9.13 uvloop-0.22.1 virtualenv-20.35.4 watchfiles-1.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install crewai groq pandas joblib scikit-learn shap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-8JXErnnw52",
        "outputId": "4f2443b4-a03d-4713-a4de-a43b4f42f56f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded model: /content/random_forest_cyber_classifier.pkl\n"
          ]
        }
      ],
      "source": [
        "import os, joblib, shap, pandas as pd, numpy as np\n",
        "from crewai import Agent, Crew\n",
        "from groq import Groq\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "llm = Groq(api_key=os.environ[\"GROQ_API_KEY\"])\n",
        "\n",
        "MODEL_PATH = \"/content/random_forest_cyber_classifier.pkl\"\n",
        "loaded = joblib.load(MODEL_PATH)\n",
        "model = loaded['model']\n",
        "label_encoder = loaded['label_encoder']\n",
        "print(f\"Loaded model: {MODEL_PATH}\")\n",
        "\n",
        "Watcher_Agent = Agent(\n",
        "    role='Watcher',\n",
        "    goal='Continuously monitor incoming network flow data and feed it into the Analyst Agent for prediction.',\n",
        "    backstory=(\n",
        "        \"You are the Watcher Agent â€” a vigilant observer of all network activity. \"\n",
        "        \"You detect new logs or packets arriving from sensors or datasets. \"\n",
        "        \"Your task is to parse and forward these observations to the Analyst Agent.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "Analyst_Agent = Agent(\n",
        "    role='Analyst',\n",
        "    goal='Use the pre-trained classical ML model to classify incoming samples as normal or anomalous.',\n",
        "    backstory=(\n",
        "        \"You are the Analyst Agent â€” the intelligence behind the cyber defense system. \"\n",
        "        \"You use a trained ML model to analyze each incoming event and predict whether it represents an attack or benign activity. \"\n",
        "        \"You then pass this result to the Remediator Agent.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "Remediator_Agent = Agent(\n",
        "    role='Remediator',\n",
        "    goal='Take corrective actions when an anomaly is detected, such as isolating nodes or alerting admins.',\n",
        "    backstory=(\n",
        "        \"You are the Remediator Agent â€” the protector of the network. \"\n",
        "        \"When the Analyst flags a potential threat, you take swift action. \"\n",
        "        \"Depending on severity, you can isolate infected nodes, update firewall rules, or trigger alerts. \"\n",
        "        \"All actions are logged for transparency.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=True,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "Explainer_Agent = Agent(\n",
        "    role='Explainer',\n",
        "    goal='Generate explainable insights for each detection using SHAP, helping analysts understand model reasoning.',\n",
        "    backstory=(\n",
        "        \"You are the Explainer Agent â€” a transparent communicator between AI models and human analysts. \"\n",
        "        \"Your job is to clarify why a sample was marked as a threat. \"\n",
        "        \"You highlight key features like SYNFlag Count or Flow Duration that influenced the modelâ€™s decision.\"\n",
        "    ),\n",
        "    verbose=True,\n",
        "    allow_delegation=False,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "crew = Crew(agents=[Watcher_Agent, Analyst_Agent, Remediator_Agent, Explainer_Agent])\n",
        "\n",
        "def analyze_event(new_data: pd.DataFrame):\n",
        "    print(\"Watcher: received new event.\")\n",
        "    features = new_data.copy()\n",
        "\n",
        "    pred = model.predict(features)\n",
        "    decoded = label_encoder.inverse_transform(pred)[0]\n",
        "    print(\"Analyst: prediction =\", decoded)\n",
        "\n",
        "    if decoded != \"Normal\":\n",
        "        remediation = f\"Alert: {decoded} attack detected. Executing mitigation and isolation protocol.\"\n",
        "    else:\n",
        "        remediation = \"No threat detected. Continue monitoring.\"\n",
        "    print(\"Remediator:\", remediation)\n",
        "\n",
        "    preprocess = model.named_steps['preprocess']\n",
        "    inner_model = model.named_steps['model']\n",
        "\n",
        "    transformed = preprocess.transform(features)\n",
        "\n",
        "    if hasattr(transformed, \"toarray\"):\n",
        "        transformed = transformed.toarray()\n",
        "\n",
        "    transformed = transformed.astype(float)\n",
        "\n",
        "    explainer = shap.TreeExplainer(inner_model, feature_perturbation=\"interventional\")\n",
        "    shap_values = explainer.shap_values(transformed, check_additivity=False)\n",
        "\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[np.argmax(inner_model.predict_proba(transformed)[0])]\n",
        "\n",
        "    ohe_cols = model.named_steps['preprocess'].named_transformers_['onehot'].get_feature_names_out(['proto','service','state'])\n",
        "    remaining_cols = [c for c in features.columns if c not in ['proto','service','state']]\n",
        "    final_feature_names = list(ohe_cols) + remaining_cols\n",
        "\n",
        "    importance_scores = np.abs(shap_values).mean(axis=0)\n",
        "    top_indices = np.argsort(importance_scores)[::-1][:5]\n",
        "    top_indices = np.array(top_indices).flatten().tolist()\n",
        "\n",
        "    top_features = [final_feature_names[i] for i in top_indices]\n",
        "\n",
        "    explanation = f\"Top influencing features: {top_features}\"\n",
        "    print(\"Explainer:\", explanation)\n",
        "\n",
        "    return {\n",
        "        \"prediction\": decoded,\n",
        "        \"remediation\": remediation,\n",
        "        \"explanation\": explanation\n",
        "    }\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pss9pDvNoV5v",
        "outputId": "6c025e82-7e5a-457f-bee5-59884e8c574a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Watcher: received new event.\n",
            "Analyst: prediction = Shellcode\n",
            "Remediator: Alert: Shellcode attack detected. Executing mitigation and isolation protocol.\n",
            "Explainer: Top influencing features: ['proto_bna', 'proto_bbn-rcc', 'proto_arp', 'proto_aris', 'proto_argus', 'proto_ax.25', 'proto_3pc', 'proto_a/n', 'proto_any', 'proto_aes-sp3-d', 'proto_bna', 'proto_3pc', 'proto_aris', 'proto_ax.25', 'proto_arp', 'proto_bbn-rcc', 'proto_a/n', 'proto_argus', 'proto_aes-sp3-d', 'proto_any', 'proto_bna', 'proto_3pc', 'proto_a/n', 'proto_ax.25', 'proto_arp', 'proto_argus', 'proto_bbn-rcc', 'proto_aes-sp3-d', 'proto_aris', 'proto_any', 'proto_bna', 'proto_bbn-rcc', 'proto_arp', 'proto_a/n', 'proto_aris', 'proto_aes-sp3-d', 'proto_argus', 'proto_ax.25', 'proto_3pc', 'proto_any', 'proto_bna', 'proto_arp', 'proto_bbn-rcc', 'proto_a/n', 'proto_argus', 'proto_aris', 'proto_3pc', 'proto_any', 'proto_ax.25', 'proto_aes-sp3-d']\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv(\"/content/Testing.csv\")\n",
        "sample = df.drop(['attack_cat','label'], axis=1).iloc[[0]]\n",
        "output = analyze_event(sample)\n",
        "print(output)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
